{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6f213c-f6ca-46ca-85c2-de61e4994c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASR packages\n",
    "import nemo.collections.asr as nemo_asr\n",
    "\n",
    "# General packages\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d43747f-9835-4aaa-b8d4-e84d3f68db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = Path(\"/home/user/code/sbb_project\")\n",
    "DATA_DIR = MAIN_DIR.joinpath(\"data_sbb\")\n",
    "TEST_DATA_DIR = DATA_DIR.joinpath(\"zeroshot_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9792fd4-98f8-4411-9407-eb87377cb0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(TEST_DATA_DIR, '*.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dbf5fed-5779-45bb-8a9c-194719473fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = \"gleis alpha vier vier via gleis beta vier f√ºnf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c3c258-d03e-48ed-865e-98604df5dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nemo_asr.models.ASRModel.list_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be3220fd-e93f-4aca-9019-5b1989bda051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-11-09 10:06:44 cloud:56] Found existing object /home/user/.cache/torch/NeMo/NeMo_1.9.0/stt_de_conformer_ctc_large/6ccf7bc56339a48fad7e06265e367dfa/stt_de_conformer_ctc_large.nemo.\n",
      "[NeMo I 2022-11-09 10:06:44 cloud:62] Re-using file from: /home/user/.cache/torch/NeMo/NeMo_1.9.0/stt_de_conformer_ctc_large/6ccf7bc56339a48fad7e06265e367dfa/stt_de_conformer_ctc_large.nemo\n",
      "[NeMo I 2022-11-09 10:06:44 common:789] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-11-09 10:06:47 mixins:166] Tokenizer SentencePieceTokenizer initialized with 128 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-09 10:06:48 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/train/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: true\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    shuffle_n: 2048\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths: /data/train/audio__OP_0..1023_CL_.tar\n",
      "    \n",
      "[NeMo W 2022-11-09 10:06:48 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /data/voxpopuli_de/dev/voxpopuli_dev_manifest.json\n",
      "    - /data/voxpopuli_de/test/voxpopuli_test_manifest.json\n",
      "    - /data/mcv7.0_de/mcv7.0_dev_manifest_cleaned.json\n",
      "    - /data/mcv7.0_de/mcv7.0_test_manifest_cleaned.json\n",
      "    - /data/mls_de/mls_dev_manifest_cleaned.json\n",
      "    - /data/mls_de/mls_test_manifest_cleaned.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: false\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2022-11-09 10:06:48 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /data/voxpopuli_de/test/voxpopuli_test_manifest.json\n",
      "    - /data/mcv7.0_de/mcv7.0_test_manifest_cleaned.json\n",
      "    - /data/mls_de/mls_test_manifest_cleaned.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: false\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-11-09 10:06:48 features:200] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-09 10:06:49 nemo_logging:349] /home/user/.local/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                    not been set for this class (WER). The property determines if `update` by\n",
      "                    default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                    achieved and we recommend setting this to `False`.\n",
      "                    We provide an checking function\n",
      "                    `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                    that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                    default for now) or if `full_state_update=False` can be used safely.\n",
      "                    \n",
      "      warnings.warn(*args, **kwargs)\n",
      "    \n",
      "[NeMo W 2022-11-09 10:06:49 nemo_logging:349] /home/user/.local/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                    not been set for this class (WERBPE). The property determines if `update` by\n",
      "                    default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                    achieved and we recommend setting this to `False`.\n",
      "                    We provide an checking function\n",
      "                    `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                    that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                    default for now) or if `full_state_update=False` can be used safely.\n",
      "                    \n",
      "      warnings.warn(*args, **kwargs)\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-11-09 10:06:51 save_restore_connector:243] Model EncDecCTCModelBPE was successfully restored from /home/user/.cache/torch/NeMo/NeMo_1.9.0/stt_de_conformer_ctc_large/6ccf7bc56339a48fad7e06265e367dfa/stt_de_conformer_ctc_large.nemo.\n"
     ]
    }
   ],
   "source": [
    "model = nemo_asr.models.ASRModel.from_pretrained(model_name='stt_de_conformer_ctc_large', strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63087cf5-9a04-444c-abc6-1d0c9cb92a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stt_nemo_transcription(model, file):\n",
    "    # get stt transcription using the pretrained model\n",
    "    transcript = model.transcribe(paths2audio_files=file)[0]\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd98e3ef-f6b0-4e83-916e-377725c111e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/user/code/sbb_project/data_sbb/zeroshot_data/Test13.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test11.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test5.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test7.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test3.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test1.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test10.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test2.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test8.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test12.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test9.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test14.wav']\n"
     ]
    }
   ],
   "source": [
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aeb3ee8-a80f-4209-8a3b-abfe1ed483a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6571501c17843d0b7bcb9ef8b94a5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b098c388a26c4134824866f11d7a2979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105dadd0198c4e829cec064cca1f9b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df78dd02ea647cbb1f86589ec316a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7c22bba84b4174ada478e4a5340c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3ca37417de4de3b7cbdccb3dabfe50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70554dd7cf5049f3a6563f828e6184ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2573d9ab78420588ade5268704f03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8d10a3da2f436cb33c0ebcc5e03054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306091f74a2d4128bec5849bb81ec57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc7410614f04561984921b387e5576a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7cd51a8dc542cf9e5b50400cd613c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = list()\n",
    "for file in files:\n",
    "    file = [file]\n",
    "    pred = get_stt_nemo_transcription(model, file)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d68f0ace-9823-48fb-99dd-3b155bb90151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preis aufa vier vier vier preis beiter vier f√ºnf', 'g√ü aufa vier vier via gles p√§d da vier fn', 'gleich aler vier vier vier gleich be√§te vier f√ºnf', 'preis auter vier vier vier greis b√§ter vier f√ºnf', 'greis aufter vier vier vier greisp√§ter vier f√ºnf', 'gleis alpha vier vier vier gleis bte vier f√ºnf', 'gleis auch von mir vier vier gleis √§ter vier fn', 'glice alpha vier vier via glece beter vier f√ºnf', 'gleich auftra vier vier vier gleis √§ta vier f√ºnf', 'glei ist auf pafier vier die ja gleich sp√§t perfierten', 'gleis aufa vier vier ja gleich √§pfa vier', 'reis auf fasste der ier vier karse der vier film']\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e749959-6f1e-46d2-bff8-c298f89dfad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer(ref, hyp ,debug=True):\n",
    "    r = ref.split()\n",
    "    h = hyp.split()\n",
    "    #costs will holds the costs, like in the Levenshtein distance algorithm\n",
    "    costs = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    "    # backtrace will hold the operations we've done.\n",
    "    # so we could later backtrace, like the WER algorithm requires us to.\n",
    "    backtrace = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    " \n",
    "    OP_OK = 0\n",
    "    OP_SUB = 1\n",
    "    OP_INS = 2\n",
    "    OP_DEL = 3\n",
    "    DEL_PENALTY = 1\n",
    "    INS_PENALTY = 1\n",
    "    SUB_PENALTY = 1\n",
    "    \n",
    "    # First column represents the case where we achieve zero\n",
    "    # hypothesis words by deleting all reference words.\n",
    "    for i in range(1, len(r)+1):\n",
    "        costs[i][0] = DEL_PENALTY*i\n",
    "        backtrace[i][0] = OP_DEL\n",
    "    \n",
    "    # First row represents the case where we achieve the hypothesis\n",
    "    # by inserting all hypothesis words into a zero-length reference.\n",
    "    for j in range(1, len(h) + 1):\n",
    "        costs[0][j] = INS_PENALTY * j\n",
    "        backtrace[0][j] = OP_INS\n",
    "    \n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                costs[i][j] = costs[i-1][j-1]\n",
    "                backtrace[i][j] = OP_OK\n",
    "            else:\n",
    "                substitutionCost = costs[i-1][j-1] + SUB_PENALTY # penalty is always 1\n",
    "                insertionCost    = costs[i][j-1] + INS_PENALTY   # penalty is always 1\n",
    "                deletionCost     = costs[i-1][j] + DEL_PENALTY   # penalty is always 1\n",
    "                 \n",
    "                costs[i][j] = min(substitutionCost, insertionCost, deletionCost)\n",
    "                if costs[i][j] == substitutionCost:\n",
    "                    backtrace[i][j] = OP_SUB\n",
    "                elif costs[i][j] == insertionCost:\n",
    "                    backtrace[i][j] = OP_INS\n",
    "                else:\n",
    "                    backtrace[i][j] = OP_DEL\n",
    "                 \n",
    "    # back trace though the best route:\n",
    "    i = len(r)\n",
    "    j = len(h)\n",
    "    numSub = 0\n",
    "    numDel = 0\n",
    "    numIns = 0\n",
    "    numCor = 0\n",
    "    if debug:\n",
    "        print(\"OP\\tREF\\tHYP\")\n",
    "        lines = []\n",
    "    while i > 0 or j > 0:\n",
    "        if backtrace[i][j] == OP_OK:\n",
    "            numCor += 1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"OK\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_SUB:\n",
    "            numSub +=1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"SUB\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_INS:\n",
    "            numIns += 1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"INS\\t\" + \"****\" + \"\\t\" + h[j])\n",
    "        elif backtrace[i][j] == OP_DEL:\n",
    "            numDel += 1\n",
    "            i-=1\n",
    "            if debug:\n",
    "                lines.append(\"DEL\\t\" + r[i]+\"\\t\"+\"****\")\n",
    "    if debug:\n",
    "        lines = reversed(lines)\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "        print(\"#cor \" + str(numCor))\n",
    "        print(\"#sub \" + str(numSub))\n",
    "        print(\"#del \" + str(numDel))\n",
    "        print(\"#ins \" + str(numIns))\n",
    "    # return (numSub + numDel + numIns) / (float) (len(r))\n",
    "    wer_result = round( (numSub + numDel + numIns) / (float) (len(r)), 3)\n",
    "    return {'WER':wer_result, 'numCor':numCor, 'numSub':numSub, 'numIns':numIns, 'numDel':numDel, \"numCount\": len(r)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9594d236-97af-4a8f-9663-a6b46eefa631",
   "metadata": {},
   "outputs": [],
   "source": [
    "wers = list()\n",
    "for pred in preds:\n",
    "    word_error = wer(pred, ground_truth, debug=False)\n",
    "    wers.append(word_error[\"WER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b011b294-5d2e-4d95-8648-4af8ff92217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preis aufa vier vier vier preis beiter vier f√ºnf', 'g√ü aufa vier vier via gles p√§d da vier fn', 'gleich aler vier vier vier gleich be√§te vier f√ºnf', 'preis auter vier vier vier greis b√§ter vier f√ºnf', 'greis aufter vier vier vier greisp√§ter vier f√ºnf', 'gleis alpha vier vier vier gleis bte vier f√ºnf', 'gleis auch von mir vier vier gleis √§ter vier fn', 'glice alpha vier vier via glece beter vier f√ºnf', 'gleich auftra vier vier vier gleis √§ta vier f√ºnf', 'glei ist auf pafier vier die ja gleich sp√§t perfierten', 'gleis aufa vier vier ja gleich √§pfa vier', 'reis auf fasste der ier vier karse der vier film']\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "832580b7-ffe0-4ed0-80b7-82a9f316f6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER for all sentences: \n",
      " [0.556, 0.6, 0.556, 0.556, 0.625, 0.222, 0.6, 0.333, 0.444, 0.9, 0.625, 0.9]\n",
      "Average WER: 0.5764166666666667 \n",
      " Minimum WER: 0.222 \n",
      " Maximum WER: 0.9\n"
     ]
    }
   ],
   "source": [
    "print(\"WER for all sentences: \\n\", wers)\n",
    "print(\"Average WER: {} \\n Minimum WER: {} \\n Maximum WER: {}\".format(np.mean(wers), np.min(wers), np.max(wers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc21cbd-15c4-448d-9895-a3bd5faaa951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
