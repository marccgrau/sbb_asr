{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6f213c-f6ca-46ca-85c2-de61e4994c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASR packages\n",
    "import nemo.collections.asr as nemo_asr\n",
    "\n",
    "# General packages\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d43747f-9835-4aaa-b8d4-e84d3f68db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = Path(\"/home/user/code/sbb_project\")\n",
    "DATA_DIR = MAIN_DIR.joinpath(\"data_sbb\")\n",
    "TEST_DATA_DIR = DATA_DIR.joinpath(\"zeroshot_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9792fd4-98f8-4411-9407-eb87377cb0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(TEST_DATA_DIR, '*.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dbf5fed-5779-45bb-8a9c-194719473fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = \"Gleis Alpha 4 4 via Gleis Beta 4 5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c3c258-d03e-48ed-865e-98604df5dc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PretrainedModelInfo(\n",
       " \tpretrained_model_name=QuartzNet15x5Base-En,\n",
       " \tdescription=QuartzNet15x5 model trained on six datasets: LibriSpeech, Mozilla Common Voice (validated clips from en_1488h_2019-12-10), WSJ, Fisher, Switchboard, and NSC Singapore English. It was trained with Apex/Amp optimization level O1 for 600 epochs. The model achieves a WER of 3.79% on LibriSpeech dev-clean, and a WER of 10.05% on dev-other. Please visit https://ngc.nvidia.com/catalog/models/nvidia:nemospeechmodels for further details.,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemospeechmodels/versions/1.0.0a5/files/QuartzNet15x5Base-En.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_models.EncDecCTCModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=asr_talknet_aligner,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:asr_talknet_aligner,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/asr_talknet_aligner/versions/1.0.0rc1/files/qn5x5_libri_tts_phonemes.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_models.EncDecCTCModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=commandrecognition_en_matchboxnet3x1x64_v1,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:commandrecognition_en_matchboxnet3x1x64_v1,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/commandrecognition_en_matchboxnet3x1x64_v1/versions/1.0.0rc1/files/commandrecognition_en_matchboxnet3x1x64_v1.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.classification_models.EncDecClassificationModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=commandrecognition_en_matchboxnet3x1x64_v2,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:commandrecognition_en_matchboxnet3x1x64_v2,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/commandrecognition_en_matchboxnet3x1x64_v2/versions/1.0.0rc1/files/commandrecognition_en_matchboxnet3x1x64_v2.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.classification_models.EncDecClassificationModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=commandrecognition_en_matchboxnet3x1x64_v2_subset_task,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:commandrecognition_en_matchboxnet3x1x64_v2_subset_task,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/commandrecognition_en_matchboxnet3x1x64_v2_subset_task/versions/1.0.0rc1/files/commandrecognition_en_matchboxnet3x1x64_v2_subset_task.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.classification_models.EncDecClassificationModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=commandrecognition_en_matchboxnet3x2x64_v1,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:commandrecognition_en_matchboxnet3x2x64_v1,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/commandrecognition_en_matchboxnet3x2x64_v1/versions/1.0.0rc1/files/commandrecognition_en_matchboxnet3x2x64_v1.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.classification_models.EncDecClassificationModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=commandrecognition_en_matchboxnet3x2x64_v2,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:commandrecognition_en_matchboxnet3x2x64_v2,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/commandrecognition_en_matchboxnet3x2x64_v2/versions/1.0.0rc1/files/commandrecognition_en_matchboxnet3x2x64_v2.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.classification_models.EncDecClassificationModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=commandrecognition_en_matchboxnet3x2x64_v2_subset_task,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:commandrecognition_en_matchboxnet3x2x64_v2_subset_task,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/commandrecognition_en_matchboxnet3x2x64_v2_subset_task/versions/1.0.0rc1/files/commandrecognition_en_matchboxnet3x2x64_v2_subset_task.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.classification_models.EncDecClassificationModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_ca_quartznet15x5,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_ca_quartznet15x5,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_ca_quartznet15x5/versions/1.0.0rc1/files/stt_ca_quartznet15x5.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_models.EncDecCTCModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_de_citrinet_1024,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_de_citrinet_1024,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_de_citrinet_1024/versions/1.3.2/files/stt_de_citrinet_1024.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_de_conformer_ctc_large,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_de_conformer_ctc_large,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_de_conformer_ctc_large/versions/1.5.0/files/stt_de_conformer_ctc_large.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_de_conformer_transducer_large,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_de_conformer_transducer_large,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_de_conformer_transducer_large/versions/1.5.0/files/stt_de_conformer_transducer_large.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_de_contextnet_1024,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_de_contextnet_1024,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_de_contextnet_1024/versions/1.4.0/files/stt_de_contextnet_1024.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_de_quartznet15x5,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_de_quartznet15x5,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_de_quartznet15x5/versions/1.0.0rc1/files/stt_de_quartznet15x5.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_models.EncDecCTCModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_citrinet_1024,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_1024,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_1024/versions/1.0.0rc1/files/stt_en_citrinet_1024.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_citrinet_1024_gamma_0_25,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_1024_gamma_0_25,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_1024_gamma_0_25/versions/1.0.0/files/stt_en_citrinet_1024_gamma_0_25.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_citrinet_256,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_256,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_256/versions/1.0.0rc1/files/stt_en_citrinet_256.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_citrinet_256_gamma_0_25,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_256_gamma_0_25,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_256_gamma_0_25/versions/1.0.0/files/stt_en_citrinet_256_gamma_0_25.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_citrinet_512,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_512,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_512/versions/1.0.0rc1/files/stt_en_citrinet_512.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_citrinet_512_gamma_0_25,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_512_gamma_0_25,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_512_gamma_0_25/versions/1.0.0/files/stt_en_citrinet_512_gamma_0_25.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_conformer_ctc_large,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_large,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_large/versions/1.6.0/files/stt_en_conformer_ctc_large.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_conformer_ctc_large_ls,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_large_ls,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_large_ls/versions/1.0.0/files/stt_en_conformer_ctc_large_ls.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_conformer_ctc_medium,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_medium,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_medium/versions/1.6.0/files/stt_en_conformer_ctc_medium.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_conformer_ctc_medium_ls,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_medium_ls,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_medium_ls/versions/1.0.0/files/stt_en_conformer_ctc_medium_ls.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_conformer_ctc_small,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_small,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_small/versions/1.6.0/files/stt_en_conformer_ctc_small.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_conformer_ctc_small_ls,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_small_ls,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_small_ls/versions/1.0.0/files/stt_en_conformer_ctc_small_ls.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_conformer_transducer_large,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_transducer_large,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_transducer_large/versions/1.6.0/files/stt_en_conformer_transducer_large.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_conformer_transducer_large_ls,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_transducer_large_ls,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_transducer_large_ls/versions/1.8.0/files/stt_en_conformer_transducer_large_ls.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_conformer_transducer_medium,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_transducer_medium,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_transducer_medium/versions/1.6.0/files/stt_en_conformer_transducer_medium.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_conformer_transducer_small,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_transducer_small,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_transducer_small/versions/1.6.0/files/stt_en_conformer_transducer_small.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_contextnet_1024,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_contextnet_1024,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_contextnet_1024/versions/1.9.0/files/stt_en_contextnet_1024.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_contextnet_1024_mls,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_contextnet_1024_mls,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_contextnet_1024_mls/versions/1.0.0/files/stt_en_contextnet_1024_mls.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_contextnet_256,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_contextnet_256,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_contextnet_256/versions/1.6.0/files/stt_en_contextnet_256.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_contextnet_256_mls,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_contextnet_256_mls,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_contextnet_256_mls/versions/1.0.0/files/stt_en_contextnet_256_mls.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_contextnet_512,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_contextnet_512,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_contextnet_512/versions/1.6.0/files/stt_en_contextnet_512.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_contextnet_512_mls,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_contextnet_512_mls,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_contextnet_512_mls/versions/1.0.0/files/stt_en_contextnet_512_mls.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_jasper10x5dr,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_jasper10x5dr,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_jasper10x5dr/versions/1.0.0rc1/files/stt_en_jasper10x5dr.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_models.EncDecCTCModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_en_quartznet15x5,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_quartznet15x5,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_quartznet15x5/versions/1.0.0rc1/files/stt_en_quartznet15x5.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_models.EncDecCTCModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_enes_conformer_ctc_large,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_enes_conformer_ctc_large,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_enes_conformer_ctc_large/versions/1.0.0/files/stt_enes_conformer_ctc_large.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_enes_conformer_transducer_large,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_enes_conformer_transducer_large,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_enes_conformer_transducer_large/versions/1.0.0/files/stt_enes_conformer_transducer_large.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_enes_contextnet_large,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_enes_contextnet_large,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_enes_contextnet_large/versions/1.0.0/files/stt_enes_contextnet_large.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_es_citrinet_1024_gamma_0_25,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_es_citrinet_1024_gamma_0_25,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_es_citrinet_1024_gamma_0_25/versions/1.8.0/files/stt_es_citrinet_1024_gamma_0_25.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_es_citrinet_512,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_es_citrinet_512,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_es_citrinet_512/versions/1.0.0/files/stt_es_citrinet_512.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_es_conformer_ctc_large,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_es_conformer_ctc_large,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_es_conformer_ctc_large/versions/1.8.0/files/stt_es_conformer_ctc_large.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_es_conformer_transducer_large,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_es_conformer_transducer_large,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_es_conformer_transducer_large/versions/1.8.0/files/stt_es_conformer_transducer_large.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_es_contextnet_1024,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_es_contextnet_1024,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_es_contextnet_1024/versions/1.8.0/files/stt_es_contextnet_1024.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_es_quartznet15x5,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_es_quartznet15x5,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_es_quartznet15x5/versions/1.0.0rc1/files/stt_es_quartznet15x5.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_models.EncDecCTCModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_fr_citrinet_1024_gamma_0_25,\n",
       " \tdescription=For details about this model, please visit https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_fr_citrinet_1024_gamma_0_25,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_fr_citrinet_1024_gamma_0_25/versions/1.5/files/stt_fr_citrinet_1024_gamma_0_25.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_fr_conformer_ctc_large,\n",
       " \tdescription=For details about this model, please visit https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_fr_conformer_ctc_large,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_fr_conformer_ctc_large/versions/1.5.1/files/stt_fr_conformer_ctc_large.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_fr_conformer_transducer_large,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_fr_conformer_transducer_large,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_de_conformer_transducer_large/versions/1.5/files/stt_fr_conformer_transducer_large.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_fr_contextnet_1024,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_fr_contextnet_1024,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_fr_contextnet_1024/versions/1.5/files/stt_fr_contextnet_1024.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_fr_no_hyphen_citrinet_1024_gamma_0_25,\n",
       " \tdescription=For details about this model, please visit https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_fr_citrinet_1024_gamma_0_25,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_fr_citrinet_1024_gamma_0_25/versions/1.5/files/stt_fr_no_hyphen_citrinet_1024_gamma_0_25.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_fr_no_hyphen_conformer_ctc_large,\n",
       " \tdescription=For details about this model, please visit https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_fr_conformer_ctc_large,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_fr_conformer_ctc_large/versions/1.5.1/files/stt_fr_no_hyphen_conformer_ctc_large.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_fr_quartznet15x5,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_fr_quartznet15x5,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_fr_quartznet15x5/versions/1.0.0rc1/files/stt_fr_quartznet15x5.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_models.EncDecCTCModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_hi_conformer_ctc_medium,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_hi_conformer_ctc_medium,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_hi_conformer_ctc_medium/versions/1.6.0/files/stt_hi_conformer_ctc_medium.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_it_quartznet15x5,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_it_quartznet15x5,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_it_quartznet15x5/versions/1.0.0rc1/files/stt_it_quartznet15x5.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_models.EncDecCTCModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_mr_conformer_ctc_medium,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_mr_conformer_ctc_medium,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_mr_conformer_ctc_medium/versions/1.6.0/files/stt_mr_conformer_ctc_medium.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_pl_quartznet15x5,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_pl_quartznet15x5,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_pl_quartznet15x5/versions/1.0.0rc1/files/stt_pl_quartznet15x5.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_models.EncDecCTCModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_ru_quartznet15x5,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_ru_quartznet15x5,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_ru_quartznet15x5/versions/1.0.0rc1/files/stt_ru_quartznet15x5.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_models.EncDecCTCModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_zh_citrinet_1024_gamma_0_25,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_zh_citrinet_1024_gamma_0_25,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_zh_citrinet_1024_gamma_0_25/versions/1.0.0/files/stt_zh_citrinet_1024_gamma_0_25.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_models.EncDecCTCModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_zh_citrinet_512,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_zh_citrinet_512,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_zh_citrinet_512/versions/1.0.0rc1/files/stt_zh_citrinet_512.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.ctc_models.EncDecCTCModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=stt_zh_conformer_transducer_large,\n",
       " \tdescription=For details about this model, please visit https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_zh_conformer_transducer_large,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_zh_conformer_transducer_large/versions/1.8.0/files/stt_zh_conformer_transducer_large.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.rnnt_models.EncDecRNNTModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=vad_marblenet,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:vad_marblenet,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/vad_marblenet/versions/1.0.0rc1/files/vad_marblenet.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.classification_models.EncDecClassificationModel'>\n",
       " ),\n",
       " PretrainedModelInfo(\n",
       " \tpretrained_model_name=vad_telephony_marblenet,\n",
       " \tdescription=For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:vad_telephony_marblenet,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/vad_telephony_marblenet/versions/1.0.0rc1/files/vad_telephony_marblenet.nemo,\n",
       " \tclass_=<class 'nemo.collections.asr.models.classification_models.EncDecClassificationModel'>\n",
       " )]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nemo_asr.models.ASRModel.list_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be3220fd-e93f-4aca-9019-5b1989bda051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-11-06 11:18:15 cloud:56] Found existing object /home/user/.cache/torch/NeMo/NeMo_1.9.0/stt_de_conformer_transducer_large/183f232a57704e78fd9b211a3e021f02/stt_de_conformer_transducer_large.nemo.\n",
      "[NeMo I 2022-11-06 11:18:15 cloud:62] Re-using file from: /home/user/.cache/torch/NeMo/NeMo_1.9.0/stt_de_conformer_transducer_large/183f232a57704e78fd9b211a3e021f02/stt_de_conformer_transducer_large.nemo\n",
      "[NeMo I 2022-11-06 11:18:15 common:789] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-11-06 11:18:20 mixins:166] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-06 11:18:21 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/train/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: true\n",
      "    num_workers: 4\n",
      "    pin_memory: true\n",
      "    use_start_end_token: true\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    shuffle_n: 2048\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths: /data/train/audio__OP_0..1023_CL_.tar\n",
      "    \n",
      "[NeMo W 2022-11-06 11:18:21 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /data/voxpopuli_de/dev/voxpopuli_dev_manifest.json\n",
      "    - /data/voxpopuli_de/test/voxpopuli_test_manifest.json\n",
      "    - /data/mcv7.0_de/mcv7.0_dev_manifest_cleaned.json\n",
      "    - /data/mcv7.0_de/mcv7.0_test_manifest_cleaned.json\n",
      "    - /data/mls_de/mls_dev_manifest_cleaned.json\n",
      "    - /data/mls_de/mls_test_manifest_cleaned.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: true\n",
      "    \n",
      "[NeMo W 2022-11-06 11:18:21 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /data/voxpopuli_de/test/voxpopuli_test_manifest.json\n",
      "    - /data/mcv7.0_de/mcv7.0_test_manifest_cleaned.json\n",
      "    - /data/mls_de/mls_test_manifest_cleaned.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-11-06 11:18:21 features:200] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-06 11:18:22 nemo_logging:349] /home/user/.local/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n",
      "[NeMo W 2022-11-06 11:18:23 rnnt:744] `experimental_fuse_loss_wer` will be deprecated in NeMo 1.6. Please use `fuse_loss_wer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-11-06 11:18:23 rnnt_models:203] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-06 11:18:23 nemo_logging:349] /home/user/.local/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                    not been set for this class (RNNTWER). The property determines if `update` by\n",
      "                    default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                    achieved and we recommend setting this to `False`.\n",
      "                    We provide an checking function\n",
      "                    `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                    that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                    default for now) or if `full_state_update=False` can be used safely.\n",
      "                    \n",
      "      warnings.warn(*args, **kwargs)\n",
      "    \n",
      "[NeMo W 2022-11-06 11:18:23 nemo_logging:349] /home/user/.local/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                    not been set for this class (RNNTBPEWER). The property determines if `update` by\n",
      "                    default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                    achieved and we recommend setting this to `False`.\n",
      "                    We provide an checking function\n",
      "                    `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                    that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                    default for now) or if `full_state_update=False` can be used safely.\n",
      "                    \n",
      "      warnings.warn(*args, **kwargs)\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-11-06 11:18:25 save_restore_connector:243] Model EncDecRNNTBPEModel was successfully restored from /home/user/.cache/torch/NeMo/NeMo_1.9.0/stt_de_conformer_transducer_large/183f232a57704e78fd9b211a3e021f02/stt_de_conformer_transducer_large.nemo.\n"
     ]
    }
   ],
   "source": [
    "model = nemo_asr.models.ASRModel.from_pretrained(model_name='stt_de_conformer_transducer_large', strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63087cf5-9a04-444c-abc6-1d0c9cb92a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stt_nemo_transcription(model, file):\n",
    "    # get stt transcription using the pretrained model\n",
    "    transcript = model.transcribe(paths2audio_files=file)[0]\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd98e3ef-f6b0-4e83-916e-377725c111e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/user/code/sbb_project/data_sbb/zeroshot_data/Test13.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test11.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test5.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test7.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test3.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test1.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test10.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test2.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test8.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test12.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test9.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test14.wav']\n"
     ]
    }
   ],
   "source": [
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aeb3ee8-a80f-4209-8a3b-abfe1ed483a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947551e01398422bbfd5fb5aa79b1b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f375d73e4c0d44e2a08c6270684f9b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee133ac719ba4709a8303bdfff18e0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1b594e00b94840a8e5e0e9535e1be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a53ef74a84249d6884f2c7ca828729b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6dc13d61702467381a76a51875f7011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375e916ad29247308c8aa7ba7cf5fff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31180bfbf7dc4d8aa461b7c60f440681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162a5d72e7284295bb4b80777f0b1186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6913cf0262694430963b002fdc4f2978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ce57de81954584a45822a25e9945ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c719f59a0aa54f48b1ad5c05c59f5235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = list()\n",
    "for file in files:\n",
    "    file = [file]\n",
    "    pred = get_stt_nemo_transcription(model, file)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d68f0ace-9823-48fb-99dd-3b155bb90151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['preis o mathia vier vier billet preis später vier fünf'], ['preis alt eher preis vier'], ['gleis alte vier wir gleis später vier fünf'], ['preis auf vier ihr preis später vier fünf'], ['preis auf vier ihr preis bitte vier fünf'], ['gleis alfa vier vier wirs bitte vier fünf'], ['gleispapier vier gleispe'], ['gleis alpha vier vierte vier fünf'], ['gleis alte gleis bitte'], ['gleich auf vier via gleich'], ['gleis auf vier gleis der vierte'], ['preis aufschaffte der pierfilme']]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e749959-6f1e-46d2-bff8-c298f89dfad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer(ref, hyp ,debug=True):\n",
    "    r = ref.split()\n",
    "    h = hyp.split()\n",
    "    #costs will holds the costs, like in the Levenshtein distance algorithm\n",
    "    costs = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    "    # backtrace will hold the operations we've done.\n",
    "    # so we could later backtrace, like the WER algorithm requires us to.\n",
    "    backtrace = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    " \n",
    "    OP_OK = 0\n",
    "    OP_SUB = 1\n",
    "    OP_INS = 2\n",
    "    OP_DEL = 3\n",
    "    DEL_PENALTY = 1\n",
    "    INS_PENALTY = 1\n",
    "    SUB_PENALTY = 1\n",
    "    \n",
    "    # First column represents the case where we achieve zero\n",
    "    # hypothesis words by deleting all reference words.\n",
    "    for i in range(1, len(r)+1):\n",
    "        costs[i][0] = DEL_PENALTY*i\n",
    "        backtrace[i][0] = OP_DEL\n",
    "    \n",
    "    # First row represents the case where we achieve the hypothesis\n",
    "    # by inserting all hypothesis words into a zero-length reference.\n",
    "    for j in range(1, len(h) + 1):\n",
    "        costs[0][j] = INS_PENALTY * j\n",
    "        backtrace[0][j] = OP_INS\n",
    "    \n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                costs[i][j] = costs[i-1][j-1]\n",
    "                backtrace[i][j] = OP_OK\n",
    "            else:\n",
    "                substitutionCost = costs[i-1][j-1] + SUB_PENALTY # penalty is always 1\n",
    "                insertionCost    = costs[i][j-1] + INS_PENALTY   # penalty is always 1\n",
    "                deletionCost     = costs[i-1][j] + DEL_PENALTY   # penalty is always 1\n",
    "                 \n",
    "                costs[i][j] = min(substitutionCost, insertionCost, deletionCost)\n",
    "                if costs[i][j] == substitutionCost:\n",
    "                    backtrace[i][j] = OP_SUB\n",
    "                elif costs[i][j] == insertionCost:\n",
    "                    backtrace[i][j] = OP_INS\n",
    "                else:\n",
    "                    backtrace[i][j] = OP_DEL\n",
    "                 \n",
    "    # back trace though the best route:\n",
    "    i = len(r)\n",
    "    j = len(h)\n",
    "    numSub = 0\n",
    "    numDel = 0\n",
    "    numIns = 0\n",
    "    numCor = 0\n",
    "    if debug:\n",
    "        print(\"OP\\tREF\\tHYP\")\n",
    "        lines = []\n",
    "    while i > 0 or j > 0:\n",
    "        if backtrace[i][j] == OP_OK:\n",
    "            numCor += 1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"OK\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_SUB:\n",
    "            numSub +=1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"SUB\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_INS:\n",
    "            numIns += 1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"INS\\t\" + \"****\" + \"\\t\" + h[j])\n",
    "        elif backtrace[i][j] == OP_DEL:\n",
    "            numDel += 1\n",
    "            i-=1\n",
    "            if debug:\n",
    "                lines.append(\"DEL\\t\" + r[i]+\"\\t\"+\"****\")\n",
    "    if debug:\n",
    "        lines = reversed(lines)\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "        print(\"#cor \" + str(numCor))\n",
    "        print(\"#sub \" + str(numSub))\n",
    "        print(\"#del \" + str(numDel))\n",
    "        print(\"#ins \" + str(numIns))\n",
    "    # return (numSub + numDel + numIns) / (float) (len(r))\n",
    "    wer_result = round( (numSub + numDel + numIns) / (float) (len(r)), 3)\n",
    "    return {'WER':wer_result, 'numCor':numCor, 'numSub':numSub, 'numIns':numIns, 'numDel':numDel, \"numCount\": len(r)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9594d236-97af-4a8f-9663-a6b46eefa631",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m wers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m preds:\n\u001b[0;32m----> 3\u001b[0m     word_error \u001b[38;5;241m=\u001b[39m \u001b[43mwer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     wers\u001b[38;5;241m.\u001b[39mappend(word_error[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWER\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mwer\u001b[0;34m(ref, hyp, debug)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwer\u001b[39m(ref, hyp ,debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m----> 2\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m()\n\u001b[1;32m      3\u001b[0m     h \u001b[38;5;241m=\u001b[39m hyp\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#costs will holds the costs, like in the Levenshtein distance algorithm\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "wers = list()\n",
    "for pred in preds:\n",
    "    word_error = wer(pred, ground_truth, debug=False)\n",
    "    wers.append(word_error[\"WER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b011b294-5d2e-4d95-8648-4af8ff92217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832580b7-ffe0-4ed0-80b7-82a9f316f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WER for all sentences: \\n\", wers)\n",
    "print(\"Average WER: \", np.mean(wers))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
