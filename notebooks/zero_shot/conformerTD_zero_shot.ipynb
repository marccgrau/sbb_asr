{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6f213c-f6ca-46ca-85c2-de61e4994c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASR packages\n",
    "import nemo.collections.asr as nemo_asr\n",
    "\n",
    "# General packages\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d43747f-9835-4aaa-b8d4-e84d3f68db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = Path(\"/home/user/code/sbb_project\")\n",
    "DATA_DIR = MAIN_DIR.joinpath(\"data_sbb\")\n",
    "TEST_DATA_DIR = DATA_DIR.joinpath(\"zeroshot_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9792fd4-98f8-4411-9407-eb87377cb0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(TEST_DATA_DIR, '*.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dbf5fed-5779-45bb-8a9c-194719473fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = \"gleis alpha vier vier via gleis beta vier fünf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92c3c258-d03e-48ed-865e-98604df5dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nemo_asr.models.ASRModel.list_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be3220fd-e93f-4aca-9019-5b1989bda051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-11-06 11:24:16 cloud:56] Found existing object /home/user/.cache/torch/NeMo/NeMo_1.9.0/stt_de_conformer_transducer_large/183f232a57704e78fd9b211a3e021f02/stt_de_conformer_transducer_large.nemo.\n",
      "[NeMo I 2022-11-06 11:24:16 cloud:62] Re-using file from: /home/user/.cache/torch/NeMo/NeMo_1.9.0/stt_de_conformer_transducer_large/183f232a57704e78fd9b211a3e021f02/stt_de_conformer_transducer_large.nemo\n",
      "[NeMo I 2022-11-06 11:24:16 common:789] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-11-06 11:24:21 mixins:166] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-06 11:24:22 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/train/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: true\n",
      "    num_workers: 4\n",
      "    pin_memory: true\n",
      "    use_start_end_token: true\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    shuffle_n: 2048\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths: /data/train/audio__OP_0..1023_CL_.tar\n",
      "    \n",
      "[NeMo W 2022-11-06 11:24:22 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /data/voxpopuli_de/dev/voxpopuli_dev_manifest.json\n",
      "    - /data/voxpopuli_de/test/voxpopuli_test_manifest.json\n",
      "    - /data/mcv7.0_de/mcv7.0_dev_manifest_cleaned.json\n",
      "    - /data/mcv7.0_de/mcv7.0_test_manifest_cleaned.json\n",
      "    - /data/mls_de/mls_dev_manifest_cleaned.json\n",
      "    - /data/mls_de/mls_test_manifest_cleaned.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: true\n",
      "    \n",
      "[NeMo W 2022-11-06 11:24:22 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /data/voxpopuli_de/test/voxpopuli_test_manifest.json\n",
      "    - /data/mcv7.0_de/mcv7.0_test_manifest_cleaned.json\n",
      "    - /data/mls_de/mls_test_manifest_cleaned.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-11-06 11:24:22 features:200] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-06 11:24:23 nemo_logging:349] /home/user/.local/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n",
      "[NeMo W 2022-11-06 11:24:24 rnnt:744] `experimental_fuse_loss_wer` will be deprecated in NeMo 1.6. Please use `fuse_loss_wer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-11-06 11:24:24 rnnt_models:203] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-06 11:24:24 nemo_logging:349] /home/user/.local/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                    not been set for this class (RNNTWER). The property determines if `update` by\n",
      "                    default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                    achieved and we recommend setting this to `False`.\n",
      "                    We provide an checking function\n",
      "                    `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                    that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                    default for now) or if `full_state_update=False` can be used safely.\n",
      "                    \n",
      "      warnings.warn(*args, **kwargs)\n",
      "    \n",
      "[NeMo W 2022-11-06 11:24:24 nemo_logging:349] /home/user/.local/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                    not been set for this class (RNNTBPEWER). The property determines if `update` by\n",
      "                    default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                    achieved and we recommend setting this to `False`.\n",
      "                    We provide an checking function\n",
      "                    `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                    that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                    default for now) or if `full_state_update=False` can be used safely.\n",
      "                    \n",
      "      warnings.warn(*args, **kwargs)\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-11-06 11:24:27 save_restore_connector:243] Model EncDecRNNTBPEModel was successfully restored from /home/user/.cache/torch/NeMo/NeMo_1.9.0/stt_de_conformer_transducer_large/183f232a57704e78fd9b211a3e021f02/stt_de_conformer_transducer_large.nemo.\n"
     ]
    }
   ],
   "source": [
    "model = nemo_asr.models.ASRModel.from_pretrained(model_name='stt_de_conformer_transducer_large', strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63087cf5-9a04-444c-abc6-1d0c9cb92a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stt_nemo_transcription(model, file):\n",
    "    # get stt transcription using the pretrained model\n",
    "    transcript = model.transcribe(paths2audio_files=file)[0]\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd98e3ef-f6b0-4e83-916e-377725c111e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/user/code/sbb_project/data_sbb/zeroshot_data/Test13.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test11.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test5.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test7.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test3.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test1.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test10.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test2.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test8.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test12.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test9.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test14.wav']\n"
     ]
    }
   ],
   "source": [
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aeb3ee8-a80f-4209-8a3b-abfe1ed483a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5ecd7a7d174b2ebb9b74769e3a758b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450ab087da6d4dc5b3b6daf5abaea3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e65ff3281f348c2b8249425eba441ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f65c4a9cfe4b1c82ae74b8201262e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86aae7d556234d42b9a7883ad9fd5820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bfa1b0475a42db9381e45428e6554d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22ad8ae030f4f969756e3498f2f04d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb65eda231794e898031a45153aa5961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3db3342a8c148f5bfb7a569a7f2d757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a2afaa0aee4a9fa1903464726e8eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692552f43670495fb2701eb845775ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4197fa69d1344e3db08b294ef1c9316a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = list()\n",
    "for file in files:\n",
    "    file = [file]\n",
    "    pred = get_stt_nemo_transcription(model, file)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d68f0ace-9823-48fb-99dd-3b155bb90151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['preis o mathia vier vier billet preis später vier fünf'], ['preis alt eher preis vier'], ['gleis alte vier wir gleis später vier fünf'], ['preis auf vier ihr preis später vier fünf'], ['preis auf vier ihr preis bitte vier fünf'], ['gleis alfa vier vier wirs bitte vier fünf'], ['gleispapier vier gleispe'], ['gleis alpha vier vierte vier fünf'], ['gleis alte gleis bitte'], ['gleich auf vier via gleich'], ['gleis auf vier gleis der vierte'], ['preis aufschaffte der pierfilme']]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e749959-6f1e-46d2-bff8-c298f89dfad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer(ref, hyp ,debug=True):\n",
    "    r = ref.split()\n",
    "    h = hyp.split()\n",
    "    #costs will holds the costs, like in the Levenshtein distance algorithm\n",
    "    costs = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    "    # backtrace will hold the operations we've done.\n",
    "    # so we could later backtrace, like the WER algorithm requires us to.\n",
    "    backtrace = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    " \n",
    "    OP_OK = 0\n",
    "    OP_SUB = 1\n",
    "    OP_INS = 2\n",
    "    OP_DEL = 3\n",
    "    DEL_PENALTY = 1\n",
    "    INS_PENALTY = 1\n",
    "    SUB_PENALTY = 1\n",
    "    \n",
    "    # First column represents the case where we achieve zero\n",
    "    # hypothesis words by deleting all reference words.\n",
    "    for i in range(1, len(r)+1):\n",
    "        costs[i][0] = DEL_PENALTY*i\n",
    "        backtrace[i][0] = OP_DEL\n",
    "    \n",
    "    # First row represents the case where we achieve the hypothesis\n",
    "    # by inserting all hypothesis words into a zero-length reference.\n",
    "    for j in range(1, len(h) + 1):\n",
    "        costs[0][j] = INS_PENALTY * j\n",
    "        backtrace[0][j] = OP_INS\n",
    "    \n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                costs[i][j] = costs[i-1][j-1]\n",
    "                backtrace[i][j] = OP_OK\n",
    "            else:\n",
    "                substitutionCost = costs[i-1][j-1] + SUB_PENALTY # penalty is always 1\n",
    "                insertionCost    = costs[i][j-1] + INS_PENALTY   # penalty is always 1\n",
    "                deletionCost     = costs[i-1][j] + DEL_PENALTY   # penalty is always 1\n",
    "                 \n",
    "                costs[i][j] = min(substitutionCost, insertionCost, deletionCost)\n",
    "                if costs[i][j] == substitutionCost:\n",
    "                    backtrace[i][j] = OP_SUB\n",
    "                elif costs[i][j] == insertionCost:\n",
    "                    backtrace[i][j] = OP_INS\n",
    "                else:\n",
    "                    backtrace[i][j] = OP_DEL\n",
    "                 \n",
    "    # back trace though the best route:\n",
    "    i = len(r)\n",
    "    j = len(h)\n",
    "    numSub = 0\n",
    "    numDel = 0\n",
    "    numIns = 0\n",
    "    numCor = 0\n",
    "    if debug:\n",
    "        print(\"OP\\tREF\\tHYP\")\n",
    "        lines = []\n",
    "    while i > 0 or j > 0:\n",
    "        if backtrace[i][j] == OP_OK:\n",
    "            numCor += 1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"OK\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_SUB:\n",
    "            numSub +=1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"SUB\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_INS:\n",
    "            numIns += 1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"INS\\t\" + \"****\" + \"\\t\" + h[j])\n",
    "        elif backtrace[i][j] == OP_DEL:\n",
    "            numDel += 1\n",
    "            i-=1\n",
    "            if debug:\n",
    "                lines.append(\"DEL\\t\" + r[i]+\"\\t\"+\"****\")\n",
    "    if debug:\n",
    "        lines = reversed(lines)\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "        print(\"#cor \" + str(numCor))\n",
    "        print(\"#sub \" + str(numSub))\n",
    "        print(\"#del \" + str(numDel))\n",
    "        print(\"#ins \" + str(numIns))\n",
    "    # return (numSub + numDel + numIns) / (float) (len(r))\n",
    "    wer_result = round( (numSub + numDel + numIns) / (float) (len(r)), 3)\n",
    "    return {'WER':wer_result, 'numCor':numCor, 'numSub':numSub, 'numIns':numIns, 'numDel':numDel, \"numCount\": len(r)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9594d236-97af-4a8f-9663-a6b46eefa631",
   "metadata": {},
   "outputs": [],
   "source": [
    "wers = list()\n",
    "for pred in preds:\n",
    "    word_error = wer(pred[0], ground_truth, debug=False)\n",
    "    wers.append(word_error[\"WER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b011b294-5d2e-4d95-8648-4af8ff92217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['preis o mathia vier vier billet preis später vier fünf'], ['preis alt eher preis vier'], ['gleis alte vier wir gleis später vier fünf'], ['preis auf vier ihr preis später vier fünf'], ['preis auf vier ihr preis bitte vier fünf'], ['gleis alfa vier vier wirs bitte vier fünf'], ['gleispapier vier gleispe'], ['gleis alpha vier vierte vier fünf'], ['gleis alte gleis bitte'], ['gleich auf vier via gleich'], ['gleis auf vier gleis der vierte'], ['preis aufschaffte der pierfilme']]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "832580b7-ffe0-4ed0-80b7-82a9f316f6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER for all sentences: \n",
      " [0.6, 1.6, 0.5, 0.75, 0.75, 0.5, 2.667, 0.667, 1.75, 1.4, 1.0, 2.25]\n",
      "Average WER: 1.2028333333333332 \n",
      " Minimum WER: 0.5 \n",
      " Maximum WER: 2.667\n"
     ]
    }
   ],
   "source": [
    "print(\"WER for all sentences: \\n\", wers)\n",
    "print(\"Average WER: {} \\n Minimum WER: {} \\n Maximum WER: {}\".format(np.mean(wers), np.min(wers), np.max(wers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc21cbd-15c4-448d-9895-a3bd5faaa951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
