{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7094576-8f4d-468f-a40f-a2d8747fcb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bec23c10-bff0-4559-8672-ff259b9296f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/user/code/sbb_asr/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "829d9e04-c4c6-4812-9abc-2cda3fc3f6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "610.44s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/code/sbb_asr/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c15935d1-0ba5-489a-815c-59aeb72fa8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbb_project import consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2053b21-2678-489b-aa29-2273e8fe95da",
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = consts.MANIFEST_DIR.joinpath(consts.MANIFEST_FILE.format('train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a34e0d21-cd33-46da-a77a-d0e1b5fb7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_dir = consts.TOKENIZER_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48520b07-870e-44fe-b108-85df03f3e4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1945.71s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-29 18:08:09 optimizers:77] Could not import distributed_fused_adam optimizer from Apex\n",
      "INFO:root:Corpus already exists at path : /home/user/code/sbb_asr/data/tokenizers/text_corpus/document.txt\n",
      "[NeMo I 2022-11-29 18:08:09 sentencepiece_tokenizer:312] Processing /home/user/code/sbb_asr/data/tokenizers/text_corpus/document.txt and store at /home/user/code/sbb_asr/data/tokenizers/tokenizer_spe_bpe_v128\n",
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/home/user/code/sbb_asr/data/tokenizers/text_corpus/document.txt --model_prefix=/home/user/code/sbb_asr/data/tokenizers/tokenizer_spe_bpe_v128/tokenizer --vocab_size=128 --shuffle_input_sentence=true --hard_vocab_limit=false --model_type=bpe --character_coverage=1.0 --bos_id=-1 --eos_id=-1\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /home/user/code/sbb_asr/data/tokenizers/text_corpus/document.txt\n",
      "  input_format: \n",
      "  model_prefix: /home/user/code/sbb_asr/data/tokenizers/tokenizer_spe_bpe_v128/tokenizer\n",
      "  model_type: BPE\n",
      "  vocab_size: 128\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 0\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: -1\n",
      "  eos_id: -1\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(350) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(181) LOG(INFO) Loading corpus: /home/user/code/sbb_asr/data/tokenizers/text_corpus/document.txt\n",
      "trainer_interface.cc(406) LOG(INFO) Loaded all 209 sentences\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(427) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(536) LOG(INFO) all chars count=15198\n",
      "trainer_interface.cc(557) LOG(INFO) Alphabet size=30\n",
      "trainer_interface.cc(558) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(590) LOG(INFO) Done! preprocessed 209 sentences.\n",
      "trainer_interface.cc(596) LOG(INFO) Tokenizing input sentences with whitespace: 209\n",
      "trainer_interface.cc(607) LOG(INFO) Done! 102\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=537 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=189 size=20 all=337 active=307 piece=▁an\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=104 size=40 all=375 active=345 piece=anöver\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=92 size=60 all=397 active=367 piece=▁acht\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=29 size=80 all=401 active=371 piece=ra\n",
      "trainer_interface.cc(685) LOG(INFO) Saving model: /home/user/code/sbb_asr/data/tokenizers/tokenizer_spe_bpe_v128/tokenizer.model\n",
      "trainer_interface.cc(697) LOG(INFO) Saving vocabs: /home/user/code/sbb_asr/data/tokenizers/tokenizer_spe_bpe_v128/tokenizer.vocab\n",
      "Serialized tokenizer at location : /home/user/code/sbb_asr/data/tokenizers/tokenizer_spe_bpe_v128\n",
      "INFO:root:Done!\n"
     ]
    }
   ],
   "source": [
    "!python ~/code/sbb_asr/src/sbb_project/training/process_asr_text_tokenizer.py \\\n",
    "  --manifest='{manifest}' \\\n",
    "  --data_root='{tokenizer_dir}' \\\n",
    "  --vocab_size=128 \\\n",
    "  --tokenizer=\"spe\" \\\n",
    "  --no_lower_case \\\n",
    "  --spe_type=\"bpe\" \\\n",
    "  --log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ebbe0-9462-456f-bd10-c18e4c28c43a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
