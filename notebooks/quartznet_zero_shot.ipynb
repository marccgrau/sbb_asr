{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6f213c-f6ca-46ca-85c2-de61e4994c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASR packages\n",
    "import nemo.collections.asr as nemo_asr\n",
    "\n",
    "# General packages\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d43747f-9835-4aaa-b8d4-e84d3f68db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = Path(\"/home/user/code/sbb_project\")\n",
    "DATA_DIR = MAIN_DIR.joinpath(\"data_sbb\")\n",
    "TEST_DATA_DIR = DATA_DIR.joinpath(\"zeroshot_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9792fd4-98f8-4411-9407-eb87377cb0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(TEST_DATA_DIR, '*.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dbf5fed-5779-45bb-8a9c-194719473fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = \"gleis alpha vier vier via gleis beta vier fünf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c3c258-d03e-48ed-865e-98604df5dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nemo_asr.models.ASRModel.list_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be3220fd-e93f-4aca-9019-5b1989bda051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-11-09 10:18:34 cloud:56] Found existing object /home/user/.cache/torch/NeMo/NeMo_1.9.0/stt_de_quartznet15x5/b82da4f9a238e099c0d94a6a0f7e8b4d/stt_de_quartznet15x5.nemo.\n",
      "[NeMo I 2022-11-09 10:18:34 cloud:62] Re-using file from: /home/user/.cache/torch/NeMo/NeMo_1.9.0/stt_de_quartznet15x5/b82da4f9a238e099c0d94a6a0f7e8b4d/stt_de_quartznet15x5.nemo\n",
      "[NeMo I 2022-11-09 10:18:34 common:789] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-09 10:18:35 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /raid/noneval.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - a\n",
      "    - b\n",
      "    - c\n",
      "    - d\n",
      "    - e\n",
      "    - f\n",
      "    - g\n",
      "    - h\n",
      "    - i\n",
      "    - j\n",
      "    - k\n",
      "    - l\n",
      "    - m\n",
      "    - 'n'\n",
      "    - o\n",
      "    - p\n",
      "    - q\n",
      "    - r\n",
      "    - s\n",
      "    - t\n",
      "    - u\n",
      "    - v\n",
      "    - w\n",
      "    - x\n",
      "    - 'y'\n",
      "    - z\n",
      "    - ä\n",
      "    - ö\n",
      "    - ü\n",
      "    - ß\n",
      "    batch_size: 32\n",
      "    trim_silence: true\n",
      "    max_duration: 16.7\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-11-09 10:18:35 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /raid/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - a\n",
      "    - b\n",
      "    - c\n",
      "    - d\n",
      "    - e\n",
      "    - f\n",
      "    - g\n",
      "    - h\n",
      "    - i\n",
      "    - j\n",
      "    - k\n",
      "    - l\n",
      "    - m\n",
      "    - 'n'\n",
      "    - o\n",
      "    - p\n",
      "    - q\n",
      "    - r\n",
      "    - s\n",
      "    - t\n",
      "    - u\n",
      "    - v\n",
      "    - w\n",
      "    - x\n",
      "    - 'y'\n",
      "    - z\n",
      "    - ä\n",
      "    - ö\n",
      "    - ü\n",
      "    - ß\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-11-09 10:18:35 features:200] PADDING: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-09 10:18:36 nemo_logging:349] /home/user/.local/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                    not been set for this class (WER). The property determines if `update` by\n",
      "                    default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                    achieved and we recommend setting this to `False`.\n",
      "                    We provide an checking function\n",
      "                    `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                    that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                    default for now) or if `full_state_update=False` can be used safely.\n",
      "                    \n",
      "      warnings.warn(*args, **kwargs)\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-11-09 10:18:37 save_restore_connector:243] Model EncDecCTCModel was successfully restored from /home/user/.cache/torch/NeMo/NeMo_1.9.0/stt_de_quartznet15x5/b82da4f9a238e099c0d94a6a0f7e8b4d/stt_de_quartznet15x5.nemo.\n"
     ]
    }
   ],
   "source": [
    "model = nemo_asr.models.ASRModel.from_pretrained(model_name='stt_de_quartznet15x5', strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63087cf5-9a04-444c-abc6-1d0c9cb92a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stt_nemo_transcription(model, file):\n",
    "    # get stt transcription using the pretrained model\n",
    "    transcript = model.transcribe(paths2audio_files=file)[0]\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd98e3ef-f6b0-4e83-916e-377725c111e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/user/code/sbb_project/data_sbb/zeroshot_data/Test13.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test11.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test5.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test7.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test3.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test1.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test10.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test2.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test8.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test12.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test9.wav', '/home/user/code/sbb_project/data_sbb/zeroshot_data/Test14.wav']\n"
     ]
    }
   ],
   "source": [
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aeb3ee8-a80f-4209-8a3b-abfe1ed483a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6578b3f2e8984056bef0e6c266bab396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3495ea040444d59143c2db3ee98f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4e794a51b24244ae83a164a719c673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7877e80f3d845aa85b09f15f4d42239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600677c7f37b44e187c450b765ec696d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ca4655303f4abeb2f3d0d8988e68a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304495c02d6e4ee889e9ad619aa497b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccf2135121441519839908a4fe3e91e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bc59ffb8854956b83a875f20c21c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82eb71c6e99846e89e1e731ccf05c551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f9432510544c308325719aa4dc4b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8e69c0d1b4449f9e7c332b2aee538c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = list()\n",
    "for file in files:\n",
    "    file = [file]\n",
    "    pred = get_stt_nemo_transcription(model, file)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e749959-6f1e-46d2-bff8-c298f89dfad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer(ref, hyp ,debug=True):\n",
    "    r = ref.split()\n",
    "    h = hyp.split()\n",
    "    #costs will holds the costs, like in the Levenshtein distance algorithm\n",
    "    costs = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    "    # backtrace will hold the operations we've done.\n",
    "    # so we could later backtrace, like the WER algorithm requires us to.\n",
    "    backtrace = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    " \n",
    "    OP_OK = 0\n",
    "    OP_SUB = 1\n",
    "    OP_INS = 2\n",
    "    OP_DEL = 3\n",
    "    DEL_PENALTY = 1\n",
    "    INS_PENALTY = 1\n",
    "    SUB_PENALTY = 1\n",
    "    \n",
    "    # First column represents the case where we achieve zero\n",
    "    # hypothesis words by deleting all reference words.\n",
    "    for i in range(1, len(r)+1):\n",
    "        costs[i][0] = DEL_PENALTY*i\n",
    "        backtrace[i][0] = OP_DEL\n",
    "    \n",
    "    # First row represents the case where we achieve the hypothesis\n",
    "    # by inserting all hypothesis words into a zero-length reference.\n",
    "    for j in range(1, len(h) + 1):\n",
    "        costs[0][j] = INS_PENALTY * j\n",
    "        backtrace[0][j] = OP_INS\n",
    "    \n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                costs[i][j] = costs[i-1][j-1]\n",
    "                backtrace[i][j] = OP_OK\n",
    "            else:\n",
    "                substitutionCost = costs[i-1][j-1] + SUB_PENALTY # penalty is always 1\n",
    "                insertionCost    = costs[i][j-1] + INS_PENALTY   # penalty is always 1\n",
    "                deletionCost     = costs[i-1][j] + DEL_PENALTY   # penalty is always 1\n",
    "                 \n",
    "                costs[i][j] = min(substitutionCost, insertionCost, deletionCost)\n",
    "                if costs[i][j] == substitutionCost:\n",
    "                    backtrace[i][j] = OP_SUB\n",
    "                elif costs[i][j] == insertionCost:\n",
    "                    backtrace[i][j] = OP_INS\n",
    "                else:\n",
    "                    backtrace[i][j] = OP_DEL\n",
    "                 \n",
    "    # back trace though the best route:\n",
    "    i = len(r)\n",
    "    j = len(h)\n",
    "    numSub = 0\n",
    "    numDel = 0\n",
    "    numIns = 0\n",
    "    numCor = 0\n",
    "    if debug:\n",
    "        print(\"OP\\tREF\\tHYP\")\n",
    "        lines = []\n",
    "    while i > 0 or j > 0:\n",
    "        if backtrace[i][j] == OP_OK:\n",
    "            numCor += 1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"OK\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_SUB:\n",
    "            numSub +=1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"SUB\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_INS:\n",
    "            numIns += 1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"INS\\t\" + \"****\" + \"\\t\" + h[j])\n",
    "        elif backtrace[i][j] == OP_DEL:\n",
    "            numDel += 1\n",
    "            i-=1\n",
    "            if debug:\n",
    "                lines.append(\"DEL\\t\" + r[i]+\"\\t\"+\"****\")\n",
    "    if debug:\n",
    "        lines = reversed(lines)\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "        print(\"#cor \" + str(numCor))\n",
    "        print(\"#sub \" + str(numSub))\n",
    "        print(\"#del \" + str(numDel))\n",
    "        print(\"#ins \" + str(numIns))\n",
    "    # return (numSub + numDel + numIns) / (float) (len(r))\n",
    "    wer_result = round( (numSub + numDel + numIns) / (float) (len(r)), 3)\n",
    "    return {'WER':wer_result, 'numCor':numCor, 'numSub':numSub, 'numIns':numIns, 'numDel':numDel, \"numCount\": len(r)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9594d236-97af-4a8f-9663-a6b46eefa631",
   "metadata": {},
   "outputs": [],
   "source": [
    "wers = list()\n",
    "for pred in preds:\n",
    "    word_error = wer(pred, ground_truth, debug=False)\n",
    "    wers.append(word_error[\"WER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b011b294-5d2e-4d95-8648-4af8ff92217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ws auch vor vier viele gliee peis betder viertel', 'es auf pa vier vier ier gleisbeter vierfen', 'gleichs auf fervier vier bir gla es päite vier fünf', 'preis auser vier vier ihr kreisspäte vier fülf', 'pris aupfer vier vier vier guareis beer vier film', 'gleis aufer vier vier vier greis bätter vier fünf', 'esakon mir hier jagar ales enter vierfer', 'gleics aufast hier vier vier reisbrätterviear finm', 'plinceautotte vier vier gleis hälte vier funge', 'noeisdau war viel vier vie jagrade seitplarwerkö', 'preis auffaf vier vier egeihete vircher', 'es au vahire iher eis heldene fife']\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "832580b7-ffe0-4ed0-80b7-82a9f316f6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER for all sentences: \n",
      " [0.889, 1.0, 0.7, 0.75, 0.667, 0.444, 1.286, 1.143, 0.714, 1.143, 1.167, 1.286]\n",
      "Average WER: 0.9324166666666667 \n",
      " Minimum WER: 0.444 \n",
      " Maximum WER: 1.286\n"
     ]
    }
   ],
   "source": [
    "print(\"WER for all sentences: \\n\", wers)\n",
    "print(\"Average WER: {} \\n Minimum WER: {} \\n Maximum WER: {}\".format(np.mean(wers), np.min(wers), np.max(wers)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
